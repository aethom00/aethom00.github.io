<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Ashton Thomas | College Student, Programmer | aethom@umich.edu</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/icons/favicon.png" rel="icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">
  
  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  <link href="footer/footer.css" rel="stylesheet">  
</head>

<body>
  <div id="headed"></div> <!-- placement for header -->

  <main id="main">

    <!-- ======= Breadcrumbs Section ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Geoguessr AI</h2>
          <ol>
            <li><a href="https://aethom00.github.io/index.html">Home</a></li>
            <li><a href="https://aethom00.github.io/index.html#portfolio">Portfolio</a></li>
            <li>Geoguessr AI</li>
          </ol>
        </div>

      </div>
    </section><!-- Breadcrumbs Section -->

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-8">
            <div class="portfolio-details-slider swiper">
              <div class="swiper-wrapper align-items-center">

                <div class="swiper-slide">
                  <img src="new_images/world-map.png" alt="">
                </div>

                <div class="swiper-slide">
                  <img src="new_images/example.png" alt="">
                </div>

                <!-- <div class="swiper-slide">
                  <img src="" alt="">
                </div> -->

              </div>
              <div class="swiper-pagination"></div>
            </div>
          </div>

          <div class="col-lg-4">
            <div class="portfolio-info">
              <h3>Project information</h3>
              <ul>
                <li><strong>Category</strong>: Python, Tensorflow, ML, Keras, PyTorch</li>
                <li><strong>Class</strong>: Computer Vision</li>
                <li><strong>Project date</strong>: Fall 2023 & Winter 2024</li>
                <li><strong>Project URL</strong>: <a href="https://aethom00.github.io/EECS_442_Final_Project.pdf" target="_blank">Click Here</a></li>
              </ul>
            </div>
            <div class="portfolio-description">
              <h2>Project Details</h2>
              <p>
                Version 1 of the project involves an AI that guesses a location given a panorama generated from an API, similar to the game Geoguessr. The AI uses random panoramas from Mapillary, converts them into grayscale, and trains a model using Keras from the Tensorflow Python library. After training, the AI makes predictions based on its trained data, with the output showing shaded boxes to indicate confidence levels, and a blue dot to show the actual location. The AI achieves a prediction accuracy rate of 90%.

                Transitioning to Version 2, we significantly enhanced the project by developing a novel computer vision model that leverages a modified ResNet-50 architecture. This new version accurately identifies geographic locations from images across the United States, regardless of lighting and seasonal variations. By fine-tuning a pre-trained model with a dataset of 61,000 images and innovating with custom layers and a unique Haversine distance-based loss function, we achieved substantial improvements in geolocation accuracy. This advancement underscores the potent applications of machine learning in real-world navigation and location-based services.
              </p>
            </div>
          </div>

        </div>

      </div>
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->

  <div id="footed"></div> 

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <script src="common_html/common.js"></script>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>
  <script src="footer/footer.js"></script>
</body>
</html>